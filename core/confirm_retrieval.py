# core/confirm_retrieval.py
import re
from core.agentstate import AgentState
from langchain.schema import Document
from bs4 import BeautifulSoup

def _clean_html(text: str) -> str:
    """HTML íƒœê·¸ ì œê±° ë° ì¤„ë°”ê¿ˆ ìœ ì§€"""
    soup = BeautifulSoup(text, "html.parser")
    text = soup.get_text(separator="\n", strip=True)
    return _prettify_text(text)

def _prettify_text(text: str) -> str:
    """í‘œÂ·ê¸°í˜¸ êµ¬ì¡°ê°€ ê¹¨ì§„ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì¢‹ê²Œ ì¬ì •ë ¬"""
    text = re.sub(r"[\u2027â€¢â€¤Â·]+", "Â·", text)        # ì¤‘ê°„ì  í†µì¼
    text = re.sub(r"\s+", " ", text)                 # ê³¼ë„í•œ ê³µë°± ì œê±°
    text = re.sub(r"(\.)([ê°€-í£])", r"\1\n\2", text) # ë¬¸ì¥ êµ¬ë¶„ì‹œ ì¤„ë°”ê¿ˆ ì¶”ê°€
    text = re.sub(r"(Â·\s*)", r"\n- ", text)          # Â· ê¸°í˜¸ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    text = re.sub(r"([ê°€-í£])(\s*:\s*)", r"\1\n", text)
    text = text.strip()
    return text

def confirm_retrieval(state: AgentState):
    """
    Human-in-the-loop í™•ì¸ ë‹¨ê³„ (CLI ë²„ì „)
    - ê²€ìƒ‰ ê²°ê³¼(ì²­í‚¹ ë°ì´í„°)ë¥¼ ì‚¬ëŒì´ ê²€í† í•˜ê³  í•„ìš” ì‹œ ì œì™¸í•  ìˆ˜ ìˆìŒ
    """
    docs = state.get("retrieved", [])
    if not docs:
        print("\n  ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤.")
        return {"route": "rewrite"}

    print("\nğŸ” === ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ===")

    # === ëª¨ë“  ê²€ìƒ‰ ë¬¸ì„œ í‘œì‹œ ===
    for i, doc in enumerate(docs):
        meta = doc.metadata
        file = meta.get("source")
        section = meta.get("section")

        clean_text = _clean_html(doc.page_content.strip())

        print(f"\nğŸ“„ [{i+1}] ë¬¸ì„œ ì •ë³´")
        print(f"   â”£ íŒŒì¼ëª…: {file}")
        print(f"   â”£ ì„¹ì…˜: {section}")
        print(f"   â”— ë‚´ìš©:\n{clean_text}")
        print("-" * 120)

    # === yes/no ì…ë ¥ ===
    while True:
        user_input = input("\nì´ ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆë‚˜ìš”? (yes/no): ").strip().lower()
        if user_input in {"yes", "y", "ì˜ˆ", "ë„¤"}:
            break
        elif user_input in {"no", "n", "ì•„ë‹ˆì˜¤", "ì•„ë‹˜"}:
            print("ğŸ”„ ì‚¬ìš©ìê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤.")
            return {"route": "rewrite"}
        else:
            print("â— 'yes' ë˜ëŠ” 'no'ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # === ì œì™¸ ë¬¸ì„œ ì„ íƒ ===
    exclude_input = input("\nì œì™¸í•  ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œ êµ¬ë¶„, ì—†ìœ¼ë©´ Enter): ").strip()
    excluded_indices = []
    if exclude_input:
        try:
            max_idx = len(docs)
            excluded_indices = [
                int(x.strip()) - 1
                for x in exclude_input.split(",")
                if x.strip().isdigit() and 1 <= int(x.strip()) <= max_idx
            ]
            display_nums = [i + 1 for i in excluded_indices]
            print(f"ğŸš« ì œì™¸ ë¬¸ì„œ ë²ˆí˜¸: {display_nums}")
        except Exception:
            print("âš ï¸ ì œì™¸ ë²ˆí˜¸ ì…ë ¥ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë¬¸ì„œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
            excluded_indices = []

    # === ìµœì¢… ì„ íƒ ë¬¸ì„œ ë°˜ì˜ ===
    selected_docs = [d for i, d in enumerate(docs) if i not in excluded_indices]
    print(f"\nâœ… {len(selected_docs)}ê°œ ë¬¸ì„œë¥¼ ìœ ì§€í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

    return {
        "retrieved": selected_docs,
        "selected": selected_docs,
        "docs_text": "\n\n".join(
            f"[{i+1}] {_clean_html(d.page_content)}" for i, d in enumerate(selected_docs)
        ),
        "sources": [
            {
                "idx": i + 1,
                "file": d.metadata.get("file", "?"),
                "section": d.metadata.get("section", "?"),
            }
            for i, d in enumerate(selected_docs)
        ],
        "route": "generate",
    }
