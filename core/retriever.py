import os
from typing import Dict, Any, List
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers.ensemble import EnsembleRetriever
from langchain.retrievers.contextual_compression import ContextualCompressionRetriever
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from langchain.retrievers.document_compressors import CrossEncoderReranker


# === Qwen API ê¸°ë°˜ Embedding í´ë˜ìŠ¤ ===
def get_qwen_api_embeddings():
    """
    Qwen3-Embedding-4B API í˜¸ì¶œ ê¸°ë°˜ Embedding
    """
    embedder_model_name = "Qwen/Qwen3-Embedding-4B"
    embedder_base_url = "http://211.47.56.71:15653/v1"
    embedder_api_key = "token-abc123"

    print(f"ğŸŒ Qwen Embedding API ì—°ê²° ì¤‘: {embedder_base_url}")
    embeddings = OpenAIEmbeddings(
        model=embedder_model_name,
        base_url=embedder_base_url,
        api_key=embedder_api_key,
    )
    return embeddings


# === RerankRetriever ì •ì˜ ===
class RerankRetriever:
    """
    Hybrid Retriever(Dense + BM25 + Cross-Encoder Reranker)
    """

    def __init__(
        self,
        faiss_db_path: str,
        reranker_model: str = "BAAI/bge-reranker-v2-m3",
        top_k: int = 10,
        ensemble_weights: tuple = (0.5, 0.5),
    ):
        self.faiss_db_path = faiss_db_path
        self.reranker_model = reranker_model
        self.top_k = top_k
        self.ensemble_weights = ensemble_weights
        self.retriever = None

        print(f"ğŸ” RerankRetriever ì´ˆê¸°í™” ì¤‘ (top_k={self.top_k})")
        self._setup()
        print("âœ… RerankRetriever ìƒì„± ì™„ë£Œ")

    def _setup(self):
        # === 1ï¸âƒ£ Qwen API Embeddings ===
        embeddings = get_qwen_api_embeddings()

        # === 2ï¸âƒ£ FAISS DB ë¡œë“œ ===
        if not os.path.exists(self.faiss_db_path):
            raise FileNotFoundError(f"âŒ DB ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.faiss_db_path}")

        content_db = FAISS.load_local(
            self.faiss_db_path,
            embeddings,
            allow_dangerous_deserialization=True
        )

        # === 3ï¸âƒ£ Dense Retriever (FAISS) ===
        dense_retriever = content_db.as_retriever(
            search_type="similarity",
            search_kwargs={"k": self.top_k}
        )

        # === 4ï¸âƒ£ Sparse Retriever (BM25) ===
        all_docs = list(content_db.docstore._dict.values())
        sparse_retriever = BM25Retriever.from_documents(all_docs)
        sparse_retriever.k = self.top_k

        # === 5ï¸âƒ£ Hybrid Retriever (Dense + Sparse) ===
        hybrid_retriever = EnsembleRetriever(
            retrievers=[sparse_retriever, dense_retriever],
            weights=list(self.ensemble_weights),
        )

        # === 6ï¸âƒ£ Cross-Encoder Reranker ===
        cross_encoder = HuggingFaceCrossEncoder(model_name=self.reranker_model)
        compressor = CrossEncoderReranker(model=cross_encoder, top_n=self.top_k)

        # === 7ï¸âƒ£ Contextual Compression Retriever ===
        self.retriever = ContextualCompressionRetriever(
            base_retriever=hybrid_retriever,
            base_compressor=compressor,
        )

    def retrieve(self, query: str) -> List[Document]:
        print(f"\nğŸ“ ì…ë ¥ ì¿¼ë¦¬: {query}")
        return self.retriever.get_relevant_documents(query)


# === LangGraphìš© Node í•¨ìˆ˜ ===
retriever_instance = RerankRetriever(
    faiss_db_path="/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/DB",
    reranker_model="BAAI/bge-reranker-v2-m3",
    top_k=8,
    ensemble_weights=(0.5, 0.5),
)


def retrieve_node(state: Dict[str, Any]) -> Dict[str, Any]:
    query = state["query"]
    docs = retriever_instance.retrieve(query)

    # ë³¸ë¬¸ + íŒŒì¼ëª…/í˜ì´ì§€ ê°™ì´ í‘œì‹œ
    docs_text = "\n\n".join(
        f"[{i+1}] ({doc.metadata.get('filename','?')} p.{doc.metadata.get('page','?')})\n{doc.page_content}"
        for i, doc in enumerate(docs)
    )

    # sources ì •ë¦¬
    sources = [
        {
            "idx": i + 1,
            "filename": doc.metadata.get("filename", ""),
            "page": doc.metadata.get("page", ""),
        }
        for i, doc in enumerate(docs)
    ]

    return {
        "retrieved": docs,
        "selected": docs,
        "docs_text": docs_text,
        "sources": sources,
    }
